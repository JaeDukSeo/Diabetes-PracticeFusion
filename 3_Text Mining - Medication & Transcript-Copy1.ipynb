{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob, os, re, random\n",
    "\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer, LancasterStemmer\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "from fuzzywuzzy import  fuzz, process\n",
    "\n",
    "from sklearn.preprocessing import Imputer, LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import cross_validation, metrics   #model optimization and valuation tools\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "def modelfit(alg,dtrain,predictors,target,scoring_method,performCV=True,printFeatureImportance=True,cv_folds=5):\n",
    "    \"\"\"\n",
    "    This functions train the model given as 'alg' by performing cross-validation. It works on both regression and classification\n",
    "    alg: sklearn model\n",
    "    dtrain: pandas.DataFrame, training set\n",
    "    predictors: list, labels to be used in the model training process. They should be in the column names of dtrain\n",
    "    target: str, target variable\n",
    "    scoring_method: str, method to be used by the cross-validation to valuate the model\n",
    "    performCV: bool, perform Cv or not\n",
    "    printFeatureImportance: bool, plot histogram of features importance or not\n",
    "    cv_folds: int, degree of cross-validation\n",
    "    \"\"\"\n",
    "    # train the algorithm on data\n",
    "    alg.fit(dtrain[predictors],dtrain[target])\n",
    "    #predict on train set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    if scoring_method == 'roc_auc':\n",
    "        dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    \n",
    "    #perform cross-validation\n",
    "    if performCV:\n",
    "        cv_score = cross_validation.cross_val_score(alg,dtrain[predictors],dtrain[target],cv=cv_folds,scoring=scoring_method)\n",
    "        #print model report\n",
    "        print \"\\nModel report:\"\n",
    "        if scoring_method == 'roc_auc':\n",
    "            print \"Accuracy:\",metrics.accuracy_score(dtrain[target].values,dtrain_predictions)\n",
    "            print \"AUC Score (Train):\",metrics.roc_auc_score(dtrain[target], dtrain_predprob)\n",
    "        if (scoring_method == 'mean_squared_error'):\n",
    "            print \"Accuracy:\",metrics.mean_squared_error(dtrain[target].values,dtrain_predictions)\n",
    "    if performCV:\n",
    "        print \"CV Score - Mean : %.7g | Std : %.7g | Min : %.7g | Max : %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score))\n",
    "    #print feature importance\n",
    "    if printFeatureImportance:\n",
    "        if dir(alg)[0] == '_Booster': #runs only if alg is xgboost\n",
    "            feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "        else:\n",
    "            feat_imp = pd.Series(alg.feature_importances_,predictors).sort_values(ascending=False)\n",
    "        feat_imp.plot(kind='bar',title='Feature Importances')\n",
    "        plt.ylabel('Feature Importe Score')\n",
    "        plt.show()\n",
    "    return alg\n",
    "\n",
    "def optimize_num_trees(alg,param_test,scoring_method,train,predictors,target):\n",
    "    \"\"\"\n",
    "    This functions is used to tune paremeters of a predictive algorithm\n",
    "    alg: sklearn model,\n",
    "    param_test: dict, parameters to be tuned\n",
    "    scoring_method: str, method to be used by the cross-validation to valuate the model\n",
    "    train: pandas.DataFrame, training data\n",
    "    predictors: list, labels to be used in the model training process. They should be in the column names of dtrain\n",
    "    target: str, target variable\n",
    "    \"\"\"\n",
    "    gsearch = GridSearchCV(estimator=alg, param_grid = param_test, scoring=scoring_method,n_jobs=2,iid=False,cv=5)\n",
    "    gsearch.fit(train[predictors],train[target])\n",
    "    return gsearch\n",
    "\n",
    "# plot optimization results\n",
    "def plot_opt_results(alg):\n",
    "    cv_results = []\n",
    "    for i in range(len(param_test['n_estimators'])):\n",
    "        cv_results.append((alg.grid_scores_[i][1],alg.grid_scores_[i][0]['n_estimators']))\n",
    "    cv_results = pd.DataFrame(cv_results)\n",
    "    plt.plot(cv_results[1],cv_results[0])\n",
    "    plt.xlabel('# trees')\n",
    "    plt.ylabel('score')\n",
    "    plt.title('optimization report')\n",
    "\n",
    "def clean_text(txt,stop_words):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    psm = PorterStemmer()\n",
    "    # make sure in put is of type str\n",
    "    if type(txt) is not str:\n",
    "        txt = str(txt)\n",
    "    #lower case\n",
    "    txt = txt.lower()\n",
    "    #remove non-alphabetic characters\n",
    "    txt = re.sub(\"[^\\s\\w]\",\" \",txt).split(\" \")\n",
    "    #txt = [str(psm.stem(wnl.lemmatize(w.strip()))) for w in txt]\n",
    "    #remove stop words\n",
    "    txt = filter(lambda w:not (w in stop_words),txt)\n",
    "    txt = ' '.join(txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a conversation with a friend experienced in medical science, she pointed out that there is a combination that can weaken a patient and sometimes triggering symptoms of diabetes mellitus. In this notebook, I am going to text mine medications with the goal to find combinations that let to diabetes in the data.\n",
    "\n",
    "The process consists in:\n",
    "\n",
    "Part I: Outsource data from webmed\n",
    "\n",
    "1. Scrape the [page of medications](http://www.webmd.com/drugs/condition-594-Type+2+Diabetes+Mellitus.aspx?diseaseid=594&diseasename=Type+2+Diabetes+Mellitus&source=2&sortColumn=1&sortDirection=a)  that were prescribe to diabetes patients. This page contains reviews from patients about the effects of those medications\n",
    "2. Clean the scrapped data and build a reference dictionary\n",
    "\n",
    "Part II: Current Data\n",
    "\n",
    "1. Convert medication names into document. Each document will be a list of words\n",
    "2. Build a vocabulary: This is hash table of all unique terms found in all documents\n",
    "3. Calculate how important each term is for each document. We will use [tf-idf](http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)\n",
    "4. Remove noisy terms. Noisy terms are those with high tf-idf in as many document as possible. Keeping in mind that the tfidf is value between 0 and 1, we can sum tf-idfs for each term in all document and set thresholds accordingly. Noisy terms will be added to the list of stop_words\n",
    "5. With the right vocabulary in hands (initial vocabulary without noisy terms), we will build a binary table with index being PatientHuid and Columns being terms in the dictionary. Each cell value will be 1 if the term has been part of medications ever prescribed to the patient of interest.\n",
    "6. compare terms in Part I to terms in Part II\n",
    "\n",
    "\n",
    "Resources:\n",
    "- http://www.webmd.com/drugs/condition-594-Type+2+Diabetes+Mellitus.aspx?diseaseid=594&diseasename=Type+2+Diabetes+Mellitus&source=2&sortColumn=1&sortDirection=a\n",
    "- http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = \"http://www.webmd.com/drugs/condition-594-Type+2+Diabetes+Mellitus.aspx?diseaseid=594&diseasename=Type+2+Diabetes+Mellitus&source=2&sortColumn=1&sortDirection=a\"\n",
    "r = requests.get(url)\n",
    "data = requests.get(url).text\n",
    "soup = BeautifulSoup(data,\"lxml\")\n",
    "\n",
    "table = soup.find('table',attrs={'class':\"drug_results_table_fmt\"})\n",
    "scrapped_meds = []\n",
    "for row in table.findAll(\"tr\"):\n",
    "    r = str(row.findAll(\"td\")[0].text)\n",
    "    r = clean_text(r,[])\n",
    "    scrapped_meds.append(r)\n",
    "#scrapped_meds = list(set(reduce(lambda x,y:x+y,scrapped_meds)))\n",
    "\n",
    "stop_words2 = ['100', '120', '200', '25', '30', '50', '60', '70', '75','oral','subcutaneous','mix','inhalation',\n",
    "               'and','pak','regular','xl','xr','injection','human']\n",
    "#corpus = medText.values.tolist()\n",
    "tf2 = TfidfVectorizer(analyzer='word',min_df=0,stop_words=stop_words2, ngram_range=(1,1))\n",
    "tf2_matrix = tf2.fit_transform(scrapped_meds)\n",
    "scrapped_meds_tfidf = pd.DataFrame(tf2_matrix.todense(),\n",
    "                                 index = scrapped_meds,\n",
    "                                 columns = sorted(tf2.vocabulary_),)\n",
    "diabetes_terms = set(scrapped_meds_tfidf.sum().index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Medication Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('data/trainingSet/training_SyncPatient.csv')\n",
    "df0.index = df0.PatientGuid\n",
    "df0 = df0.drop('PatientGuid',axis=1).sort_index()\n",
    "\n",
    "df1 = pd.read_csv('data/trainingSet/training_SyncMedication.csv')\n",
    "df1 = df1[~df1.MedicationName.isnull()]\n",
    "patient_medication = df1[['PatientGuid','MedicationName']]\n",
    "patient_medication.MedicationName+=' '\n",
    "patient_medication = patient_medication.groupby('PatientGuid').sum().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To do**\n",
    "\n",
    "- remove all characters which are not alphatic\n",
    "- remove buzz words\n",
    "- find similarity between words. Some medical terms can be from same family, so I want these to be grouped together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tic = dt.datetime.now()\n",
    "stop_words1 = [' ','','oral','tablet','capsule','release','topical','extended','nasal','inhalation',\n",
    "              'with','delayed','coated','enteric','aerosol','spray','metoprotol','solution','cream',\n",
    "              'sodium','syrup','d','adapter','tab','tabs','10','100','104','disintegrating','acid','intravenous',\n",
    "             '1000','11','12','120','12d','13','15','150','16','1a','1b','1x','20','200','2011','2012','21',\n",
    "              '23','24','24d','25','28','30','300','325','3350','35','40','400','50','500','60','600','625',\n",
    "              '2a','64','650','750','75','80','81','900','acids','and','at','device','di','dr','easy','ii','in',\n",
    "              'iv','mg','non','of','oil','pack','packet','packets','poly','top','subcutaneous','mix','inhalation',\n",
    "               'and','pak','regular','xl','xr','injection','human']\n",
    "stop_words_ = [' ','',\n",
    "              'with', '10','100','104',\n",
    "             '1000','11','12','120','12d','13','15','150','16','1a','1b','1x','20','200','2011','2012','21',\n",
    "              '23','24','24d','25','28','30','300','325','3350','35','40','400','50','500','60','600','625',\n",
    "              '2a','64','650','750','75','80','81','900','and','at','ii','in',\n",
    "              'iv','mg','non','of','poly','top','subcutaneous','mix','inhalation',\n",
    "               'and','pak','regular','xl','xr','injection','human']\n",
    "medText = patient_medication.MedicationName.apply(lambda w:clean_text(w,stop_words1))\n",
    "corpus = medText.values.tolist()\n",
    "tf1 = TfidfVectorizer(analyzer='word',min_df=0,stop_words=stop_words1, ngram_range=(1,1))\n",
    "tf1_matrix = tf1.fit_transform(corpus)\n",
    "medications_tfidf = pd.DataFrame(tf1_matrix.todense(),\n",
    "                                 index = patient_medication.index,\n",
    "                                 columns = sorted(tf1.vocabulary_),)\n",
    "medications_tfidf['DMIndicator'] = df0.DMIndicator\n",
    "print \"process time:\", dt.datetime.now() - tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_agg = medications_tfidf.sum().sort_values(ascending=False)\n",
    "d_tfidf_agg = -(tfidf_agg - tfidf_agg.shift())#.sort_values()\n",
    "tfidf_agg.plot()\n",
    "d_tfidf_agg.plot()\n",
    "plt.yscale('log')\n",
    "plt.title(\"Aggregate Term Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words+=tfidf_agg[tfidf_agg>100].index.tolist()\n",
    "medText = patient_medication.MedicationName.apply(lambda w:clean_text(w,stop_words))\n",
    "corpus = medText.values.tolist()\n",
    "tf = TfidfVectorizer(analyzer='word',min_df=0,stop_words=stop_words, ngram_range=(1,1))\n",
    "tfidf_matrix = tf.fit_transform(corpus)\n",
    "medications_tfidf = pd.DataFrame(tfidf_matrix.todense(),\n",
    "                                 index = patient_medication.index,\n",
    "                                 columns = sorted(tf.vocabulary_),)\n",
    "\n",
    "medications_tfidf['DMIndicator'] = df0.DMIndicator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "We use MedicationName available in current medication dataset and cross check it with the set of scrapped meds ever taken by diabetes to find diabetes related medications. These medications will be given higher weight in the modeling part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_taken_meds(text,ref_terms=diabetes_terms):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    s1 = set(clean_text(text,stop_words1).split(\" \"))\n",
    "    s2 = set(ref_terms)\n",
    "    r = s1.intersection(s2)\n",
    "    if len(r) == 0:\n",
    "        return 'NoMeds'\n",
    "    else:\n",
    "        return list(r)\n",
    "\n",
    "patient_medication['DMIndicator'] = df0.DMIndicator\n",
    "patient_medication['TakenMeds'] = patient_medication.MedicationName.apply(lambda x:get_taken_meds(x))\n",
    "positive_meds = list(set(patient_medication[patient_medication.TakenMeds != 'NoMeds']['TakenMeds'].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['welchol',\n",
       " 'miglitol',\n",
       " 'glyset',\n",
       " 'nateglinide',\n",
       " 'bromocriptine',\n",
       " 'colesevelam',\n",
       " 'acarbose',\n",
       " 'cycloset',\n",
       " 'micronized']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_meds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels0 = medications_tfidf.columns[:-1]\n",
    "labels1 = positive_meds\n",
    "target = 'DMIndicator'\n",
    "_Xtrain,_Xvalid,_Ytrain,_Yvalid = train_test_split(medications_tfidf[labels0],\n",
    "                                                   medications_tfidf[target],test_size=1/4.,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df = medications_tfidf[medications_tfidf.columns[:-1]].sum().sort_values(ascending=False)\n",
    "#df.plot()\n",
    "#plt.show()\n",
    "\n",
    "#labels1 = df[df>=10].index.tolist()\n",
    "#target = 'DMIndicator'\n",
    "#_Xtrain,_Xvalid,_Ytrain,_Yvalid = train_test_split(medications_tfidf[labels1],\n",
    "#                                                   medications_tfidf[target],test_size=1/4.,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC:"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-759ad40c3c32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Xtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_Ytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Xvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"ROC AUC:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mypred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_Yvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    258\u001b[0m     return _average_binary_score(\n\u001b[1;32m    259\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/metrics/base.pyc\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[1;32m    252\u001b[0m                              \"is not defined in that case.\")\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(_Xtrain,_Ytrain)\n",
    "ypred = mnb.predict(_Xvalid)\n",
    "print \"ROC AUC:\", metrics.roc_auc_score(ypred,_Yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2366"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'human', u'injection'], dtype='object')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['welchol',\n",
       " 'miglitol',\n",
       " 'glyset',\n",
       " 'nateglinide',\n",
       " 'bromocriptine',\n",
       " 'colesevelam',\n",
       " 'acarbose',\n",
       " 'cycloset',\n",
       " 'micronized']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_meds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
